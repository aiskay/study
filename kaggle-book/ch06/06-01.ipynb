{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 6.1 パラメータチューニング\n",
    "\n",
    "## 6.1.1 ハイパーパラメータの探索手法\n",
    "\n",
    "1. 手動\n",
    "2. グリッドサーチ/ランダムサーチ  \n",
    "   パラメータ空間を予め指定した範囲を規則的に探索/予め指定した手法でランダムに探索  \n",
    "   `sckikit-learn.model_selection` の `GridSearchCV`, `RandomizedSearchCV` など\n",
    "3. ベイズ最適化 (Bayseian Optimization)  \n",
    "    以前に計算したパラメータの履歴に基づいてベイズの手法を用いて選択  \n",
    "    `hyperopt`, `optuna` など\n",
    "\n",
    "kaggle でのパラメータ探索は手で行っている人が多い印象。\n",
    "\n",
    "## 6.1.2 パラメータチューニングで設定すること\n",
    "\n",
    "1. ベースラインとなるパラメータ\n",
    "2. 探索する対象となるパラメータとその範囲\n",
    "3. 手動で調節するか、自動的に探索するか\n",
    "4. 評価の枠組み (fold の分け方など)\n",
    "\n",
    "パラメータを自動で調節する場合には、\n",
    "\n",
    "- パラメータチューニングをしすぎて学習データに過剰に適合してしまう\n",
    "- 計算時間が長くなる\n",
    "\n",
    "といった問題が起こり得るので、\n",
    "\n",
    "- チューニングとモデルの作成をする際の fold の分け方を変える\n",
    "- validation の fold の 1 つだけを用いて精度を確認する\n",
    "\n",
    "などの対策をしたほうが良い。\n",
    "\n",
    "## 6.1.3 パラメータチューニングのポイント\n",
    "\n",
    "各モデルには結果を大きく左右する大事なパラメータが存在する。  \n",
    "そのため、パラメータを探索する際はその**モデルの重要なパラメータから調節していく**ことが大事である。  \n",
    "\n",
    "また、**モデルとパラメータの関係を理解して得られた結果からなぜそうなったのかを理解すること**で、次にどうパラメータを変化させるべきかを考えながらチューニングしていくとよい。\n",
    "\n",
    "なお、GBDT ではパラメータチューニングよりも良い特徴量を追加するほうが有用なことが多いので、あまりチューニングに時間を割かない方が良い。\n",
    "\n",
    "\n",
    "## 6.1.4 ベイズ最適化でのパラメータ探索\n",
    "\n",
    "Tree-structured Parzen Estimator (TPE) というアルゴリズムを用いて最適化を行っている `hyperopt` と `optuna` について、以下具体的な使い方を見ていく。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ---------------------------------\n",
    "# データ等の準備\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]  # 最初の fold のみ用いる\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "# xgboostによる学習・予測を行うクラス\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        params = {'objective': 'binary:logistic', 'eval_metric': 'error', 'verbosity': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.model = xgb.train(params, dtrain, num_round, verbose_eval=False, evals=watchlist)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [`hyperopt`](http://hyperopt.github.io/hyperopt/)\n",
    "\n",
    "具体的な手順は以下のよう。\n",
    "\n",
    "1. 最小化したい評価指標を返す関数を作成する (`score` function) \n",
    "2. 探索するパラメータ範囲を定義する (`space` 変数)\n",
    "3. 探索回数を指定する (`max_eval` 変数)\n",
    "\n",
    "以上を `hyperopt.fmin` 関数に代入して探索を行う。\n",
    "\n",
    "経験的には 25 回程度の探索でそれなりに妥当なパラメータが見つかり始め、100 回程度で十分な探索が行われるようである。\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# -----------------------------------\n",
    "# hyperopt を使ったパラメータ探索\n",
    "# -----------------------------------\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    # パラメータを与えたときに最小化する評価指標を指定する\n",
    "    # 具体的には、モデルにパラメータを指定して学習・予測させた場合のスコアを返すようにする\n",
    "\n",
    "    # max_depthの型を整数型に修正する\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "    # Modelクラスを定義しているものとする\n",
    "    # Modelクラスは、fitで学習し、predictで予測値の確率を出力する\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    # 情報を記録しておく\n",
    "    history.append((params, score))\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# 探索するパラメータの空間を指定する\n",
    "# hp.choiceでは、複数の選択肢から選ぶ\n",
    "# hp.uniformでは、下限・上限を指定した一様分布から抽出する。引数は下限・上限\n",
    "# hp.quniformでは、下限・上限を指定した一様分布のうち一定の間隔ごとの点から抽出する。引数は下限・上限・間隔\n",
    "# hp.loguniformでは、下限・上限を指定した対数が一様分布に従う分布から抽出する。引数は下限・上限の対数をとった値\n",
    "space = {\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 5, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 9, 1),\n",
    "    'gamma': hp.quniform('gamma', 0, 0.4, 0.1),\n",
    "}\n",
    "\n",
    "# hyperoptによるパラメータ探索の実行\n",
    "max_evals = 20\n",
    "trials = Trials()\n",
    "history = []\n",
    "fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "# 記録した情報からパラメータとスコアを出力する\n",
    "# （trialsからも情報が取得できるが、パラメータの取得がやや行いづらいため）\n",
    "history = sorted(history, key=lambda tpl: tpl[1])\n",
    "best = history[0]\n",
    "print(f'best params:{best[0]}, score:{best[1]:.4f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [`optuna`](https://optuna.readthedocs.io/en/stable/)\n",
    "\n",
    "2018 年末に公開されたフレームワークで、最適化のアルゴリズムに TPE を用いているのは hyperopt と同じだが、\n",
    "\n",
    "- 学習曲線を用いた試行の枝切り\n",
    "- 並列分散最適化\n",
    "\n",
    "といった点でより効率的になっている。\n",
    "\n",
    "以下で見るように確かに簡単に使えるし、個人的に最近よく聞くのはこっちな気がする。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# -----------------------------------\n",
    "# optuna を使ったパラメータ探索\n",
    "# -----------------------------------\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'gamma': trial.suggest_uniform('gamma', 0, 0.4),\n",
    "    }\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f'best params:{study.best_params}, score:{study.best_value:.4f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ただ、ベイズ最適化によるチューニングでは以下のような問題が生じることがある。\n",
    "\n",
    "- 計算時間のかかりすぎる試行  \n",
    "  学習率を小さくした場合は学習がなかなか進まなくなってしまうので、事前に調整しておくなどの対策が必要。\n",
    "- パラメータ間の依存性\n",
    "  チューニングされるパラメータ同士は完全に独立でないため、依存性が強く表れる場合は効率的な探索ができない可能性がある。  \n",
    "  パラメータ空間を明示的にするか、試行回数を増やす必要がある。\n",
    "- 評価のランダム性によるばらつき\n",
    "  評価のぶれが大きいときは効果的に探索できないので、cross validation の平均で評価するなど試行回数を増やすなどの必要がある。\n",
    "\n",
    "従って、ベイズ最適化を使う場合はこれらの点に注意すること。\n",
    "\n",
    "## 6.1.5 GBDT のパラメータおよびそのチューニング\n",
    "\n",
    "ここでは、GBDT の例として xgboost のパラメータを見ていく。  \n",
    "なお、lightgbm も考え方はほぼ同じである。\n",
    "\n",
    "| parameter          | explanation                                                      | \n",
    "| :----------------: | :--------------------------------------------------------------: | \n",
    "| `eta`              | 学習率 (予測値のアップデートの際に予測誤差に乗じられる)              | \n",
    "| `num_round`        | 決定木の本数                                                     | \n",
    "| `max_depth`        | 決定木の深さ                                                     | \n",
    "| `min_child_weight` | 葉を分岐するために必要な最低限のデータ数                         | \n",
    "| `gamma`            | 決定木を分岐させるために最低限減らさなくてはいけない目的関数の値 | \n",
    "| `colsample_bytree` | 決定木ごとに特徴量の列をサンプリングする割合                     | \n",
    "| `subsmaple`        | 決定機ごとに学習データの行をサンプリングする割合                 | \n",
    "| `alpha`            | 決定木の葉の weight に対する L1 正則化の強さ                      | \n",
    "| `lambda`           | 決定木の葉の weight に対する L2 正則化の強さ                      | \n",
    "\n",
    "まずは、学習率などといった最重要のパラメータを以下の方針で決定する。\n",
    "\n",
    "- `eta` を小さくしすぎると学習に時間がかかるようになるので、初めのうちは 0.1 程度にしより精度を求める段階になれば 0.01 - 0.05 程度にする \n",
    "- `num_round` は 1000 程度と大きくしておいて、`early_stopping_rounds` で制御する\n",
    "- `early_stopping_rounds` は 50 程度で十分\n",
    "\n",
    "次に、以下の学習の複雑さに関するパラメータを順次調節する。  \n",
    "経験的には `max_depth` が最も重要であるらしい。\n",
    "\n",
    "- `max_depth`, `min_child_weight`, `gamma`  \n",
    "- `alpha`, `lambda`\n",
    "- `subsample`, `colsample_bytree`\n",
    "\n",
    "具体的なチューニングの例は p.318 - p.320 の COLUMN を参考に。(結構大事な気がしている)\n",
    "\n",
    "## 6.1.6 ニューラルネットのパラメータおよびそのチューニング\n",
    "\n",
    "調節対象となり得るパラメータ\n",
    "\n",
    "- ネットワークの構成\n",
    "  - 中間層の活性化関数 (基本は ReLU $f(x) = \\max (0, x)$)\n",
    "  - 中間層の層数\n",
    "  - 各層のユニット数、ドロップアウト率\n",
    "  - Batch normalization 層をどうするか  \n",
    "  Batch normalization とは、ネットワーク内でデータの分布が偏ってしまうことを防ぐためにデータを標準化する手法。  \n",
    "  大きな学習係数が使える・正則化効果があるなどのメリットがあるらしい\n",
    "- オプティマイザの選択  \n",
    "SGD と Adam などを試してみるとよい\n",
    "- その他\n",
    "  - バッチサイズ\n",
    "  - weight decay (cost function の L2 regularization) などの正則化の導入やオプティマイザの学習率以外の調整\n",
    "\n",
    "Neural net の場合、目的関数の発散を防ぐためまずは学習率を調整し、次にその他のパラメータを調節するとよい。  \n",
    "\n",
    "Neural net のパラメータの詳しい設定・チューニングについては 4.4.6 を、\n",
    "具体的なチューニングの例は p.321 - p.326 の COLUMN を参考に。\n",
    "\n",
    "## 6.1.7 線形モデルのパラメータおよびそのチューニング\n",
    "\n",
    "線形モデルでは正則化のパラメータがチューニング対象となる[<sup>1</sup>](#fn1)。  \n",
    "対象のパラメータが少なく計算も比較的早いので、広範囲を探索することが可能である。\n",
    "\n",
    "\n",
    "<span id=\"fn1\"> [正則化（Ridge,Lasso）](https://qiita.com/greatonbi/items/0323d420af46d3ed9183) </span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}